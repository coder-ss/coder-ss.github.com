<!doctype html>



  


<html class="theme-next mist use-motion">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />












  
  
  <link href="/vendors/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/vendors/font-awesome/css/font-awesome.min.css?v=4.4.0" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.0.2" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="机器学习,线性代数,矩阵分析," />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.png?v=5.0.2" />






<meta name="description" content="线性代数、矩阵论中的一些知识。">
<meta property="og:type" content="article">
<meta property="og:title" content="机器学习之矩阵基础">
<meta property="og:url" content="http://coder-ss.github.io/2016/05/10/machine_learning/matrix/index.html">
<meta property="og:site_name" content="coder_ss's blog">
<meta property="og:description" content="线性代数、矩阵论中的一些知识。">
<meta property="og:image" content="http://7qn7rt.com1.z0.glb.clouddn.com/ml/matrix/2line.png">
<meta property="og:image" content="http://7qn7rt.com1.z0.glb.clouddn.com/ml/matrix/3plant.png">
<meta property="og:image" content="http://7qn7rt.com1.z0.glb.clouddn.com/ml/matrix/2dimesion.png">
<meta property="og:image" content="http://7qn7rt.com1.z0.glb.clouddn.com/ml/matrix/3dimension.png">
<meta property="og:image" content="http://7qn7rt.com1.z0.glb.clouddn.com/ml/matrix/4spaces.png">
<meta property="og:image" content="http://7qn7rt.com1.z0.glb.clouddn.com/ml/matrix/eigen_value.png">
<meta property="og:image" content="http://7qn7rt.com1.z0.glb.clouddn.com/ml/matrix/svd.png">
<meta property="og:updated_time" content="2017-02-24T14:12:24.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="机器学习之矩阵基础">
<meta name="twitter:description" content="线性代数、矩阵论中的一些知识。">
<meta name="twitter:image" content="http://7qn7rt.com1.z0.glb.clouddn.com/ml/matrix/2line.png">



<script type="text/javascript" id="hexo.configuration">
  var NexT = window.NexT || {};
  var CONFIG = {
    scheme: 'Mist',
    sidebar: {"position":"left","display":"post"},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: '博主'
    }
  };
</script>




  <link rel="canonical" href="http://coder-ss.github.io/2016/05/10/machine_learning/matrix/"/>


  <title> 机器学习之矩阵基础 | coder_ss's blog </title>
</head>

<body itemscope itemtype="//schema.org/WebPage" lang="zh-Hans">

  



  <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "//hm.baidu.com/hm.js?7d7157a5836d43e3ad7dbd42e82697f3";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>








  
  
    
  

  <div class="container one-collumn sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="//schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta ">
  

  <div class="custom-logo-site-title">
    <a href="/"  class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <span class="site-title">coder_ss's blog</span>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>
  <p class="site-subtitle">do something interesting</p>
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
            标签
          </a>
        </li>
      

      
    </ul>
  

  
</nav>

 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="//schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                机器学习之矩阵基础
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2016-05-10T21:35:00+08:00" content="2016-05-10">
              2016-05-10
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/machine-learning/" itemprop="url" rel="index">
                    <span itemprop="name">machine_learning</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
              <span class="post-comments-count">
                &nbsp; | &nbsp;
                <a href="/2016/05/10/machine_learning/matrix/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2016/05/10/machine_learning/matrix/" itemprop="commentsCount"></span>
                </a>
              </span>
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        <h2 id="Ax-b-的两种理解"><a href="#Ax-b-的两种理解" class="headerlink" title="Ax=b 的两种理解"></a>Ax=b 的两种理解</h2><blockquote>
<p>基于列视图来理解 $A\boldsymbol{x}=b$，可以更好的理解矩阵。</p>
</blockquote>
<p>分别对于二元线性方程组</p>
<script type="math/tex; mode=display">\left\{
\begin{align*}
2x-y &=1 \\
x+y &= 5 \\
\end{align*}
\right.</script><p>和三元线性方程组</p>
<script type="math/tex; mode=display">\left\{
\begin{align*}
2x+y+z &=5 \\
4x-6y &= -2 \\
-2x+7y+2z&=9\\
\end{align*}
\right.</script><p>分别讨论他们的<strong>行视图</strong>与<strong>列视图</strong>。</p>
<h3 id="行视图"><a href="#行视图" class="headerlink" title="行视图"></a>行视图</h3><p>二元线性方程组理解为：在 $ XOY $ 坐标轴系中直线 $ 2x-y=1 $ 与 直线 $ x+y=5 $ 的交点。</p>
<p><img src="http://7qn7rt.com1.z0.glb.clouddn.com/ml/matrix/2line.png" alt="Alt text"></p>
<p>三元线性方程组理解为：在 $ XYZ $ 坐标系中平面 $ 2x+y+z =5 $ 与平面 $ 4x-6y = 0 $ 与平面 $ -2x+7y+2z=9 $  的交点（前两个平面交于一条直线，这条直线与第三个平面交于一点）。</p>
<p><img src="http://7qn7rt.com1.z0.glb.clouddn.com/ml/matrix/3plant.png" alt="Alt text"></p>
<h3 id="列视图"><a href="#列视图" class="headerlink" title="列视图"></a>列视图</h3><script type="math/tex; mode=display">x\left[ \begin{aligned}2 \\ 1 \\ \end{aligned}\right]+y\left[ \begin{aligned}-1 \\ 1 \\ \end{aligned}\right]=\left[ \begin{aligned}1 \\ 5 \\ \end{aligned}\right]</script><p>二元线性方程组理解为：向量 $ \left[ \begin{aligned}2 \\ 1 \\ \end{aligned}\right] $ 与向量 $     \left[ \begin{aligned}-1 \\ 1 \\ \end{aligned}\right] $ 按一定比例缩放以后相加的结果等于向量 $     \left[ \begin{aligned}1 \\ 5 \\ \end{aligned}\right] $</p>
<p><img src="http://7qn7rt.com1.z0.glb.clouddn.com/ml/matrix/2dimesion.png" alt="Alt text"></p>
<p>三元线性方程组理解为：向量 $ \left[ \begin{matrix}2 \\ 4 \\ -2 \\ \end{matrix}\right] $ 与向量 $     \left[ \begin{matrix}1 \\ -6 \\ 7 \\ \end{matrix}\right] $ 与向量 $     \left[ \begin{matrix}1 \\ 0 \\ 2 \\ \end{matrix}\right] $ 按一定比例缩放以后相加的结果等于向量 $     \left[ \begin{matrix}5 \\ -2 \\ 9 \\ \end{matrix}\right] $</p>
<p><img src="http://7qn7rt.com1.z0.glb.clouddn.com/ml/matrix/3dimension.png" alt="Alt text"></p>
<h2 id="4个基本子空间"><a href="#4个基本子空间" class="headerlink" title="4个基本子空间"></a>4个基本子空间</h2><blockquote>
<p><strong>基础概念：</strong></p>
<p>线性组合：一些向量的任意标量乘法之和<br>$ \text{span} \lbrace \boldsymbol{v_1},\boldsymbol{v_2},…,\boldsymbol{v_p} \rbrace $：所有可以表示成 $\boldsymbol{v_1},…,\boldsymbol{v_p}$ 的线性组合的向量集合（所有可以由 $\boldsymbol{v_1},…,\boldsymbol{v_p}$ 线性表出的向量的集合）</p>
</blockquote>
<h3 id="列空间（column-space）"><a href="#列空间（column-space）" class="headerlink" title="列空间（column space）"></a>列空间（column space）</h3><p>$ m \times n $ 维矩阵 $ A $ 的<strong>列空间</strong> $ C(A) $ 是由 $ A $ 的列的所有线性组合组成的集合。<br>$ C(A) $ 中的一个典型向量可以写成 $ A\boldsymbol{x} $ 的形式，其中 $ \boldsymbol{x} $ 为某向量，因为 $ A\boldsymbol{x} $ 表示 $ A $ 的列向量的线性组合。即$ C(A) $ 是线性变换 $ \boldsymbol{x} \mapsto A\boldsymbol{x} $ 的值域。</p>
<ul>
<li>$ C(A) $ 是 $\mathbb{R}^m$ 的一个子空间    </li>
<li>$ A $的一个最大线性无关向量组就是 $ C(A) $ 的一组基。</li>
</ul>
<blockquote>
<p><strong>例：</strong><br>矩阵$ A＝ \left[ \begin{matrix} 1 &amp; 0 \\ 4 &amp; 3 \\ 2 &amp; 3 \end{matrix}\right] $ 的列空间 $ C(A)= \text{span} \lbrace \boldsymbol{a_1},\boldsymbol{a_2}\rbrace $ 是 $ \mathbb{R}^3 $ 的一个子空间 ，其中 $ \boldsymbol{a_1}=\left[ \begin{matrix} 1 \\ 4 \\ 2 \end{matrix}\right] $、$ \boldsymbol{a_2}=\left[ \begin{matrix} 0 \\ 3 \\ 3 \end{matrix}\right] $</p>
</blockquote>
<h3 id="零空间（null-space）"><a href="#零空间（null-space）" class="headerlink" title="零空间（null space）"></a>零空间（null space）</h3><p>$ m \times n $ 维矩阵 $ A $ 的零空间 $ N(A) $ 是齐次方程 $ A\boldsymbol{x}=\boldsymbol{0} $ 解的集合。  </p>
<ul>
<li><p>$ N(A) $ 是 $\mathbb{R}^n$ 的一个子空间</p>
</li>
<li><p>求$ N(A) $的过程就是求$ A\boldsymbol{x}=\boldsymbol{0} $ 的通解的过程</p>
</li>
</ul>
<blockquote>
<p><strong>例：</strong><br>求矩阵 $ A=\left[ \begin{matrix} 1 &amp; 2 &amp; 2 &amp; 4 \\ 3 &amp; 8 &amp; 6 &amp; 16 \\ \end{matrix}\right] $ 的零空间，即先求$ \left[ \begin{matrix} 1 &amp; 2 &amp; 2 &amp; 4 \\ 3 &amp; 8 &amp; 6 &amp; 16 \\ \end{matrix}\right]\boldsymbol{x}= \left[ \begin{matrix} 0 \\ 0\end{matrix} \right]$ 的通解。<br>将 $ A $ 化为阶梯型矩阵$ \left[ \begin{matrix} 1 &amp; 0 &amp; 2 &amp; 0 \\ 0 &amp; 1 &amp; 0 &amp; 2 \\ \end{matrix}\right] $，即$ \left\lbrace\begin{align*} x_1 &amp;=-2x_3 \\ x_2 &amp;= -2x_4 \\ \end{align*} \right.$，可得通解：</p>
<script type="math/tex; mode=display">\left[ \begin{matrix} x_1 \\ x_2 \\ x_3 \\ x_4 \end{matrix}\right]=c_1\left[ \begin{matrix}-2\\0\\1\\0 \end{matrix}\right] + c_2\left[ \begin{matrix}0\\-2\\0\\1 \end{matrix}\right]</script><p>所以，零空间 $ N(A) $ 为 $ \mathbb{R}^4 $ 的一个子空间<br>为<br>$ N(A)= \text{span} \lbrace \boldsymbol{v_1},\boldsymbol{v_2} \rbrace $，其中$ \boldsymbol{v_1}=\left[ \begin{matrix}-2\\0\\1\\0 \end{matrix}\right] $、$ \boldsymbol{v_1}=\left[ \begin{matrix}0\\-2\\0\\1 \end{matrix}\right] $<br>$ N(A) $ 为 $ \mathbb{R}^4 $ 的一个子空间</p>
</blockquote>
<h3 id="行空间（row-space）"><a href="#行空间（row-space）" class="headerlink" title="行空间（row space）"></a>行空间（row space）</h3><p>$ m \times n $ 维矩阵 $ A $ 的<strong>行空间</strong> $ C(A^T) $ 是由 $ A $ 的行的所有线性组合组成的集合。</p>
<ul>
<li>$ C(A^T) $ 是 $\mathbb{R}^n$ 的一个子空间</li>
</ul>
<h3 id="左零空间（left-null-space）"><a href="#左零空间（left-null-space）" class="headerlink" title="左零空间（left null space）"></a>左零空间（left null space）</h3><p>$ m \times n $ 维矩阵 $ A $ 的左零空间 $ N(A^T) $ 是齐次方程 $ A^T\boldsymbol{x}=\boldsymbol{0} $ 解的集合。 </p>
<ul>
<li>$ N(A^T) $ 是 $\mathbb{R}^m$ 的一个子空间</li>
</ul>
<h3 id="4个子空间的关系"><a href="#4个子空间的关系" class="headerlink" title="4个子空间的关系"></a>4个子空间的关系</h3><p><img src="http://7qn7rt.com1.z0.glb.clouddn.com/ml/matrix/4spaces.png" alt="Alt text"></p>
<ul>
<li>左邻空间的向量与列空间的向量相垂直（内积为零）</li>
<li>左邻空间与列空间交于向量 $ \boldsymbol{0} $</li>
<li>列空间的维数（最大线性无关的向量个数、秩、基的个数）为 $ r $，左邻空间的维数为 $ m-r $</li>
<li>零空间的向量与行空间的向量相垂直</li>
<li>行空间的维数（最大线性无关的向量个数、秩、基的个数）为 $ r $（矩阵行向量的秩等于列向量的秩），零空间的维数为 $ n-r $</li>
</ul>
<h3 id="利用子空间判断线性方程组的解"><a href="#利用子空间判断线性方程组的解" class="headerlink" title="利用子空间判断线性方程组的解"></a>利用子空间判断线性方程组的解</h3><p>$ A\boldsymbol{x}=b $ 的解</p>
<ul>
<li>只有唯一解，则 $ \boldsymbol{b} \in C(A) $，且 $ N(A) $ 的维数是0</li>
<li>有无穷多个解，$ \boldsymbol{b} \in C(A) $，且 $N(A)$ 的维数大于0</li>
<li>无解，则$ \boldsymbol{b} \notin C(A) $</li>
</ul>
<h2 id="特征分解"><a href="#特征分解" class="headerlink" title="特征分解"></a>特征分解</h2><h3 id="特征值与特征向量"><a href="#特征值与特征向量" class="headerlink" title="特征值与特征向量"></a>特征值与特征向量</h3><blockquote>
<p><strong>定义：</strong><br>设 $A$ 是 $n$ 阶矩阵，如果数 $\lambda$ 和 $n$ 维非零列向量 $\boldsymbol{x}$ 使关系式</p>
<script type="math/tex; mode=display">A\boldsymbol{x}=\lambda\boldsymbol{x}</script><p>成立，那么，这样的数 $\lambda$ 成为矩阵 $A$ 的<strong>特征值</strong>，非零向量 $\boldsymbol{x}$ 称为 $A$ 的对应于特征值 $\lambda$ 的<strong>特征向量</strong>。</p>
</blockquote>
<h3 id="A-boldsymbol-x-lambda-boldsymbol-x-的几何意义"><a href="#A-boldsymbol-x-lambda-boldsymbol-x-的几何意义" class="headerlink" title="$ A\boldsymbol{x}=\lambda\boldsymbol{x} $ 的几何意义"></a>$ A\boldsymbol{x}=\lambda\boldsymbol{x} $ 的几何意义</h3><p>变换 $ \boldsymbol{x}\mapsto A\boldsymbol{x} $ 与变换 $ \boldsymbol{x}\mapsto\lambda\boldsymbol{x} $ 是等价的。即，经过变换 $ \boldsymbol{x}\mapsto A\boldsymbol{x} $ 后的向量与 $\boldsymbol{x}$ 向量共线（方向相同或相反）。</p>
<blockquote>
<p><strong>例：</strong><br>给定矩阵 $ A=\left[\begin{matrix} 4&amp;1 \\ 1&amp;4 \end{matrix}\right] $，<br>对 $ \boldsymbol{x_1}=\left[\begin{matrix} 1 \\ 0\end {matrix}\right] $，有 $ A\boldsymbol{x} =\left[\begin{matrix} 4 \\ 1\end {matrix}\right] $；<br>对 $ \boldsymbol{x_2}=\left[\begin{matrix} 0 \\ 1\end {matrix}\right] $，有 $ A\boldsymbol{x}=\left[ \begin{matrix} 1 \\ 4\end {matrix}\right] $；<br>对 $ \boldsymbol{x_3}=\left[\begin{matrix} 1 \\ 1\end {matrix}\right] $，有 $ A\boldsymbol{x}=5\left[ \begin{matrix} 1 \\ 1\end {matrix}\right] =5\boldsymbol{x_3}$。<br><img src="http://7qn7rt.com1.z0.glb.clouddn.com/ml/matrix/eigen_value.png" alt="Alt text"></p>
</blockquote>
<h3 id="特征分解-1"><a href="#特征分解-1" class="headerlink" title="特征分解"></a>特征分解</h3><h4 id="一般矩阵"><a href="#一般矩阵" class="headerlink" title="一般矩阵"></a>一般矩阵</h4><p><strong>相似矩阵：</strong> $n$ 阶矩阵 $A$、$B$，若有可逆矩阵 $P$，使</p>
<script type="math/tex; mode=display">P^{-1}AP=B</script><p>则称 $B$ 是 $A$ 的相似矩阵。</p>
<p> <strong>对角化定理：</strong>  $n$ 阶矩阵 $A$ 与对角矩阵 $\Lambda$ 相似（即 $A$ 能对角化）的充分必要条件是 $A$ 有 $n$ 个线性无关的特征向量。</p>
<p><strong>推论：</strong> 如果 $n$ 阶矩阵 $A$ 的 $n$ 个特征值互不相等，则 $A$ 与对角矩阵相似。</p>
<blockquote>
<p><strong>证明：</strong><br>假设存在可逆矩阵 $P$，使 $P^{-1}AP=\Lambda$ 为对角矩阵，$P$ 用其列向量表示为</p>
<script type="math/tex; mode=display">P=(\boldsymbol{p_1},\boldsymbol{p_2},...,\boldsymbol{p_n})</script><p>由 $P^{-1}AP=\Lambda$，有 $AP=P\Lambda$，即</p>
<script type="math/tex; mode=display">
\begin{aligned}
A(\boldsymbol{p_1},\boldsymbol{p_2},...,\boldsymbol{p_n}) &= 
(\boldsymbol{p_1},\boldsymbol{p_2},...,\boldsymbol{p_n})
\left[\begin{matrix}
\lambda_1\\&\lambda_2\\&&\ddots\\&&&\lambda_n
\end{matrix}\right] \\ &=(\lambda_1\boldsymbol{p_1},\lambda_2\boldsymbol{p_2},...,\lambda_n\boldsymbol{p_n})
\end{aligned}</script><p>于是</p>
<script type="math/tex; mode=display">A\boldsymbol{p}_i=\lambda_i\boldsymbol{p_i} \ (i=1,2,...,n)</script><p>可见 $\lambda_i$ 是$A$ 的特征值，而 $P$ 的列向量 $\boldsymbol{p_i}$ 就是 $A$ 的对应于特征值 $\lambda_i$ 的特征向量。<br>而且，因为P可逆，所以 $\boldsymbol{p_1},\boldsymbol{p_2},…,\boldsymbol{p_n}$ 线性无关。</p>
</blockquote>
<h4 id="对称矩阵"><a href="#对称矩阵" class="headerlink" title="对称矩阵"></a>对称矩阵</h4><p>对 $n\times n$ 的对称矩阵 $A$：</p>
<ul>
<li>$A$ 特征值为实数。且有 $n$ 个特征值（包含重复的特征值）</li>
<li>$A$ 的不同特征值对应的特征向量相互正交（$\boldsymbol{p_1}^T\boldsymbol{p_2}=0$）</li>
<li>秩$r=Rank(A)\leq n$，即<script type="math/tex">\underbrace{ |\lambda_1|\geq |\lambda_2|\geq ...\geq|\lambda_r|}_{r}>\underbrace{\lambda_{r+1}=...=\lambda_n}_{n-r}=0</script></li>
<li>$ \text{Rank} (A^TA) = \text{Rank} (AA^T) = \text{Rank}(A) = \text{Rank}(\Lambda)$</li>
<li>$A$ 可正交对角化</li>
</ul>
<blockquote>
<p><strong>证明不同特征值（$\lambda_1\neq \lambda_2$）对应的特征向量正交（$\boldsymbol{p_1^T\boldsymbol{p_2}}=0$）：</strong><br>因 $A$ 对称，故$\lambda_1\boldsymbol{p_1^T}=(\lambda_1\boldsymbol{p_1})^T= (A\boldsymbol{p_1})^T= \boldsymbol{p_1^T}A^T=\boldsymbol{p_1^T}A$，于是</p>
<script type="math/tex; mode=display">\lambda_1\boldsymbol{p_1^T}\boldsymbol{p_2}=\boldsymbol{p_1^T}A\boldsymbol{p_2}=\boldsymbol{p_1^T}\lambda_2\boldsymbol{p_2}=\lambda_2\boldsymbol{p_1^T}\boldsymbol{p_2}</script><p>即</p>
<script type="math/tex; mode=display">(\lambda_1-\lambda_2)\boldsymbol{p_1^T\boldsymbol{p_2}}=0</script><p>但 $\lambda_1\neq \lambda_2$，所以 $\boldsymbol{p_1^T\boldsymbol{p_2}}=0$，即 $\boldsymbol{p_1}$ 与 $\boldsymbol{p_2}$ 正交。</p>
</blockquote>
<p><strong>谱分解：</strong></p>
<p>对 $n$ 阶对称矩阵 $A$，必有正交矩阵 $P$，使 $P^{-1}AP=P^TAP=\Lambda$：</p>
<script type="math/tex; mode=display">\begin{align*}
A&=P\Lambda P^T  \\
&=[\boldsymbol{p_1},\boldsymbol{p_2},\cdots,\boldsymbol{p_n}] \left[\begin{matrix}\lambda_1\\& \lambda_2\\&&\ddots\\&&& \lambda_n \end{matrix}\right]\left[\begin{matrix}\boldsymbol{p_1^T} \\\boldsymbol{p_2^T}\\\vdots\\\boldsymbol{p_n^T}\end{matrix}\right] \\
&=\lambda_1\boldsymbol{p_1}\boldsymbol{p_1^T}+\lambda_2\boldsymbol{p_2}\boldsymbol{p_2^T}+\cdots+\lambda_n\boldsymbol{p_n}\boldsymbol{p_n^T} \\
&=\sum_{i=1}^{n}\lambda_i\boldsymbol{p_i}\boldsymbol{p_i^T}
\end{align*}</script><p>上述式子分解为A的谱（特征值）确定的小块，所以称为谱分解。</p>
<h3 id="二次型（Quadratic-Form）"><a href="#二次型（Quadratic-Form）" class="headerlink" title="二次型（Quadratic Form）"></a>二次型（Quadratic Form）</h3><p>对 $n\times n$ 阶的对称矩阵 $A$，函数</p>
<script type="math/tex; mode=display">f(\boldsymbol{x})=\sum_{i,j=1}^{n} a_{ij}x_ix_j=\boldsymbol{x^T}A\boldsymbol{x}</script><p>被称为二次型。</p>
<blockquote>
<p><strong>通过函数的二次型推导矩阵的二次型：</strong><br>二次齐次函数</p>
<script type="math/tex; mode=display">\begin{align*}
f(x_1,x_2,\cdots,x_n)&=a_{11}x_1^2+a_{22}x_2^2+\cdots+a_{nn}x_n^2 \\
&\quad+2a_{12}x_1x_2+2a_{13}x_1x_3+\cdots+2a_{n-1,n}x_{n-1}x_n
\end{align*}</script><p>称为二次型（所有项全部为2次）<br>当 $j&gt;i$ 时，取$a_{ij}=a_{ji}$，则$2a_{ij}x_i x_j=a_{ij} x_i x_j + a_{ji} x_j x_i$，于是</p>
<script type="math/tex; mode=display">\begin{align*}
f&=a_{11}x_1^2+a_{12}x_1x_2+\cdots+a_{1n}x_1x_n \\
&\quad+a_{21}x_2x_1+a_{22}x_2^2+\cdots+a_{2n}x_2x_n \\
&\quad+\cdots \\
&\quad+a_{n1}x_nx_1+a_{n2}x_nx_2+\cdots+a_{nn}x_n^2\\
&=\sum_{i,j=1}^{n}a_{ij}x_ix_j \\
&=x_1(a_{11}x_1+a_{12}x_2+\cdots+a_{1n}x_n) \\
&\quad+x_2(a_{21}x_1+a_{22}x_2+\cdots+a_{2n}x_n) \\
&\quad+\cdots \\
&\quad+x_n(a_{n1}x_1+a_{n2}x_2+\cdots+a_{nn}x_n) \\
&=\left[x_1,x_2,\cdots,x_n\right]\left[\begin{matrix} a_{11}x_1+a_{12}x_2+\cdots+a_{1n}x_n \\a_{21}x_1+a_{22}x_2+\cdots+a_{2n}x_n \\ \vdots \\a_{n1}x_1+a_{n2}x_2+\cdots+a_{nn}x_n \end{matrix}\right] \\
&=\left[x_1,x_2,\cdots,x_n\right]\left[\begin{matrix} a_{11} & a_{12} & \cdots & a_{1n} \\a_{21}&a_{22}&\cdots&a_{2n} \\ \vdots&\vdots&&\vdots \\a_{n1}&a_{n2}&\cdots&a_{nn}\end{matrix}\right]\left[\begin{matrix} x_1\\x_2\\\vdots\\x_n\end{matrix}\right] \\
&=\boldsymbol{x^T}A\boldsymbol{x}
\end{align*}</script></blockquote>
<h3 id="正定二次型"><a href="#正定二次型" class="headerlink" title="正定二次型"></a>正定二次型</h3><p>设二次型 $f(\boldsymbol{x})=\boldsymbol{x^T}A\boldsymbol{x}$，如果对任何 $\boldsymbol{x}\neq \boldsymbol{0}$，都有 $f(\boldsymbol{x})&gt;0$（显然 $f(\boldsymbol{0})=0$），则称 $f$ 为正定二次型，并称对称矩阵 $A$ 是正定的；如果对于任何 $\boldsymbol{x}\neq \boldsymbol{0}$ 都有 $f(\boldsymbol{x})&lt;0$，则称 $f$ 为负定二次型，并称对称矩阵 $A$ 是负定的。</p>
<ul>
<li>半正定（positive semidefinite）：$f\geq 0$</li>
<li>正定（positive definite）：$f&gt;0$</li>
<li>负定（negative definite）：$f&lt;0$</li>
<li>不定（indefinite）</li>
</ul>
<p><strong>对称矩阵 $A$ 为正定的充分必要条件是：$A$ 的特征值全为正</strong></p>
<h3 id="特征分解的应用：PCA"><a href="#特征分解的应用：PCA" class="headerlink" title="特征分解的应用：PCA"></a>特征分解的应用：PCA</h3><blockquote>
<p>PCA：Principal Component Analysis 主成分分析，用于降维</p>
</blockquote>
<p>先不考虑降维，先考虑如下的一个变换。<br>对$m\times n$矩阵 $X$，我们希望经过一个变换 $Y=QX$ （$Q\in \mathbb{R}^{m\times m}$）使 $Y$ 的<strong>协方差矩阵为对角阵</strong>。协方差矩阵为对角阵意味着行向量之间的协方差为0，而每个行向量的方差尽可能大。</p>
<p>$X$ 的协方差矩阵为：</p>
<script type="math/tex; mode=display">C_X=\frac{1}{n}XX^T</script><p>例如</p>
<script type="math/tex; mode=display">X=\left[\begin{matrix}a_1&a_2&\cdots&a_n \\
b_1&b_2&\cdots&b_n\end{matrix}\right]</script><p>时，协方差矩阵为：</p>
<script type="math/tex; mode=display">C_X=\frac{1}{n}\left[\begin{matrix}a_1&a_2&\cdots&a_n\\
b_1&b_2&\cdots&b_n\end{matrix}\right] 
\left[\begin{matrix}a_1&b_1\\
a_2&b_2\\\vdots&\vdots\\a_n&b_n\end{matrix}\right]
=\left[\begin{matrix}
\frac{1}{n}\sum_{i=1}^{n} a_i^2 & \frac{1}{n}\sum_{i=1}^{n} a_ib_i \\
\frac{1}{n}\sum_{i=1}^{n} a_ib_i & \frac{1}{n}\sum_{i=1}^{n} b_i^2
\end{matrix}\right]</script><p>所以，有 $Y$ 的协方差矩阵：</p>
<script type="math/tex; mode=display">C_Y=\frac{1}{n}YY^T=\frac{1}{n}(QX)(QX)^T=\frac{1}{n}QXX^TQ^T=QC_XQ^T</script><p>我们的目的就是求 $Q$ 使 $C_Y$ 为对角阵。利用特征分解，我们可以将对称矩阵 $C_X$ 对角化：</p>
<script type="math/tex; mode=display">P^{-1}C_XP=P^TC_XP=\Lambda</script><p>其中，$P$ 的列向量为 $C_X$ 的特征向量，$\Lambda$是 $C_X$ 的特征值组成的矩阵。 结合上面两个式子，显然有</p>
<script type="math/tex; mode=display">Q=P^{-1}=P^T</script><blockquote>
<p><strong>示例</strong></p>
<script type="math/tex; mode=display">X=\left[\begin{matrix}-1&-1&0&2&0 \\ -2&0&0&1&1\end{matrix}\right]</script><p>可求得</p>
<script type="math/tex; mode=display">C_X=\left[\begin{matrix} \frac{6}{5}& \frac{4}{5} \\ \frac{4}{5} & \frac{6}{5} \end{matrix}\right]</script><p>计算 $C_X$ 的特征值 $\lambda_1$、$\lambda_2$，特征向量 $\boldsymbol{p_1}$、$\boldsymbol{p_2}$，得</p>
<script type="math/tex; mode=display">\begin{align*}C_X&= P\Lambda P^T  \\
&=[\boldsymbol{p_1},\boldsymbol{p_2}] \left[\begin{matrix}\lambda_1\\& \lambda_2 \end{matrix}\right]\left[\begin{matrix}\boldsymbol{p_1^T} \\\boldsymbol{p_2^T}\end{matrix}\right] \\
&=\left[\begin{matrix} \frac{1}{\sqrt{2}} &-\frac{1}{\sqrt{2}}\\ \frac{1}{\sqrt{2}}&\frac{1}{\sqrt{2}}  \end{matrix}\right] \left[\begin{matrix}2 &\\ &\frac{2}{5} \end{matrix}\right] \left[\begin{matrix} \frac{1}{\sqrt{2}} &\frac{1}{\sqrt{2}}\\ -\frac{1}{\sqrt{2}}&\frac{1}{\sqrt{2}}  \end{matrix}\right]
\end{align*}</script><p>因此</p>
<script type="math/tex; mode=display">\begin{align*}Y&=QX=P^TX \\
&= \left[\begin{matrix}\boldsymbol{p_1^T}\\\boldsymbol{p_2^T} \end{matrix}\right]X\\
&=\left[\begin{matrix} \frac{1}{\sqrt{2}} &\frac{1}{\sqrt{2}}\\ -\frac{1}{\sqrt{2}}&\frac{1}{\sqrt{2}}  \end{matrix}\right] \left[\begin{matrix}-1&-1&0&2&0 \\ -2&0&0&1&1\end{matrix}\right] \\
&=\left[\begin{matrix}-\frac{3}{\sqrt{2}}&-\frac{1}{\sqrt{2}}&0&\frac{3}{\sqrt{2}}&\frac{1}{\sqrt{2}} \\ -\frac{1}{\sqrt{2}} & \frac{1}{\sqrt{2}} &0&-\frac{1}{\sqrt{2}}& \frac{1}{\sqrt{2}}\end{matrix}\right]
\end{align*}</script><p>可以观察到Y中的每一行，都是X的一个特征向量的转置与X相乘的结果，即 $Y=\left[\begin{matrix}y_1^T \\ y_2^T\end{matrix}\right]=\left[\begin{matrix}\boldsymbol{p_1^T}X \\ \boldsymbol{p_2^T}X\end{matrix}\right]$</p>
</blockquote>
<p>再考虑降维。<br>上面例子中$C_X$ 的两个特征值 $\lambda_1=2$、$\lambda_2=\frac{2}{5}$，相对来说 $\lambda_1$ 比 $\lambda_2$大不少，而</p>
<script type="math/tex; mode=display">\begin{align*}C_X= P\Lambda P^T  
=[\boldsymbol{p_1},\boldsymbol{p_2}] \left[\begin{matrix}\lambda_1\\& \lambda_2 \end{matrix}\right]\left[\begin{matrix}\boldsymbol{p_1^T} \\\boldsymbol{p_2^T}\end{matrix}\right] 
=\lambda_1\boldsymbol{p_1}\boldsymbol{p_1^T}+\lambda_2\boldsymbol{p_2}\boldsymbol{p_2^T}
\end{align*}</script><p>因此，我们可以只取等式最右边第一项 $ \lambda_1\boldsymbol{p_1}\boldsymbol{p_1^T} $ 来近似描述 $ C_X $，即 $ P=[\boldsymbol{p_1}] $。进一步地，</p>
<script type="math/tex; mode=display">
\begin{align*}Y&=QX=P^TX=\boldsymbol{p_1^T}X \\
&=\left[\begin{matrix} \frac{1}{\sqrt{2}} &\frac{1}{\sqrt{2}}  \end{matrix}\right] \left[\begin{matrix}-1&-1&0&2&0 \\ -2&0&0&1&1\end{matrix}\right] \\
&=\left[\begin{matrix}-\frac{3}{\sqrt{2}}&-\frac{1}{\sqrt{2}}&0&\frac{3}{\sqrt{2}}&\frac{1}{\sqrt{2}}\end{matrix}\right]
\end{align*}</script><p>从而达到了降维的目的。</p>
<p>因为之前没有接触PCA，这里只按照程博的讲解纪录了降维的原理和步骤，实际运用中肯定有很大不同（程博的讲解也提到了实际中PCA可能不是用特征分解而是SVD，因为特征分解的性质不好等balabala），总结PCA的要点：</p>
<ul>
<li>KL变换来的，本质是把协方差矩阵对角化。</li>
<li>对角化：使不同行向量间的协方差为0，每个行向量的方差尽可能大。</li>
</ul>
<h2 id="SVD"><a href="#SVD" class="headerlink" title="SVD"></a>SVD</h2><blockquote>
<p>Singular Value Decomposition 奇异值分解</p>
</blockquote>
<p><img src="http://7qn7rt.com1.z0.glb.clouddn.com/ml/matrix/svd.png" alt="Alt text"></p>
<h2 id="矩阵导数"><a href="#矩阵导数" class="headerlink" title="矩阵导数"></a>矩阵导数</h2><ul>
<li>$Y=AX$，$\frac{D(Y)}{D(X)} = A^T$</li>
<li>$Y=XA$，$\frac{D(Y)}{D(X)} = A$</li>
<li>$Y=A^TXB$，$\frac{D(Y)}{D(X)} = AB^T$</li>
<li>$Y=A^TX^TB$，$\frac{D(Y)}{D(X)} = BA^T$</li>
<li>$\frac{D(Y^T)}{D(X)} = \frac{D(Y)}{D(X)} $</li>
</ul>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul>
<li>七月算法机器学习课程</li>
<li>矩阵分析与应用 张贤达</li>
</ul>

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/机器学习/" rel="tag">#机器学习</a>
          
            <a href="/tags/线性代数/" rel="tag">#线性代数</a>
          
            <a href="/tags/矩阵分析/" rel="tag">#矩阵分析</a>
          
        </div>
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2016/05/08/machine_learning/probability_statistics/" rel="next" title="机器学习之概率统计基础">
                <i class="fa fa-chevron-left"></i> 机器学习之概率统计基础
              </a>
            
          </div>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2016/11/02/http/http-summary/" rel="prev" title="HTTP报文总结">
                HTTP报文总结 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
      <div class="ds-thread" data-thread-key="2016/05/10/machine_learning/matrix/"
           data-title="机器学习之矩阵基础" data-url="http://coder-ss.github.io/2016/05/10/machine_learning/matrix/">
      </div>
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel ">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="//schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/favicon.png"
               alt="coder-ss" />
          <p class="site-author-name" itemprop="name">coder-ss</p>
          <p class="site-description motion-element" itemprop="description">do something interesting</p>
        </div>
        <nav class="site-state motion-element">
          <div class="site-state-item site-state-posts">
            <a href="/archives">
              <span class="site-state-item-count">24</span>
              <span class="site-state-item-name">日志</span>
            </a>
          </div>

          
            <div class="site-state-item site-state-categories">
              <a href="/categories">
                <span class="site-state-item-count">6</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            <div class="site-state-item site-state-tags">
              <a href="/tags">
                <span class="site-state-item-count">26</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        

      </section>

      
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">
            
              
            
            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#Ax-b-的两种理解"><span class="nav-number">1.</span> <span class="nav-text">Ax=b 的两种理解</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#行视图"><span class="nav-number">1.1.</span> <span class="nav-text">行视图</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#列视图"><span class="nav-number">1.2.</span> <span class="nav-text">列视图</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4个基本子空间"><span class="nav-number">2.</span> <span class="nav-text">4个基本子空间</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#列空间（column-space）"><span class="nav-number">2.1.</span> <span class="nav-text">列空间（column space）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#零空间（null-space）"><span class="nav-number">2.2.</span> <span class="nav-text">零空间（null space）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#行空间（row-space）"><span class="nav-number">2.3.</span> <span class="nav-text">行空间（row space）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#左零空间（left-null-space）"><span class="nav-number">2.4.</span> <span class="nav-text">左零空间（left null space）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4个子空间的关系"><span class="nav-number">2.5.</span> <span class="nav-text">4个子空间的关系</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#利用子空间判断线性方程组的解"><span class="nav-number">2.6.</span> <span class="nav-text">利用子空间判断线性方程组的解</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#特征分解"><span class="nav-number">3.</span> <span class="nav-text">特征分解</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#特征值与特征向量"><span class="nav-number">3.1.</span> <span class="nav-text">特征值与特征向量</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#A-boldsymbol-x-lambda-boldsymbol-x-的几何意义"><span class="nav-number">3.2.</span> <span class="nav-text">$ A\boldsymbol{x}=\lambda\boldsymbol{x} $ 的几何意义</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#特征分解-1"><span class="nav-number">3.3.</span> <span class="nav-text">特征分解</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#一般矩阵"><span class="nav-number">3.3.1.</span> <span class="nav-text">一般矩阵</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#对称矩阵"><span class="nav-number">3.3.2.</span> <span class="nav-text">对称矩阵</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#二次型（Quadratic-Form）"><span class="nav-number">3.4.</span> <span class="nav-text">二次型（Quadratic Form）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#正定二次型"><span class="nav-number">3.5.</span> <span class="nav-text">正定二次型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#特征分解的应用：PCA"><span class="nav-number">3.6.</span> <span class="nav-text">特征分解的应用：PCA</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#SVD"><span class="nav-number">4.</span> <span class="nav-text">SVD</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#矩阵导数"><span class="nav-number">5.</span> <span class="nav-text">矩阵导数</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#参考资料"><span class="nav-number">6.</span> <span class="nav-text">参考资料</span></a></li></ol></div>
            
          </div>
        </section>
      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2017</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">coder-ss</span>
</div>

<div class="powered-by">
  由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Mist
  </a>
</div>

        

        
      </div>
    </footer>

    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>
    </div>
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  



  
  <script type="text/javascript" src="/vendors/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/vendors/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/vendors/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/vendors/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/vendors/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/vendors/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.0.2"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.0.2"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.0.2"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.0.2"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.0.2"></script>



  

  
    
  

  <script type="text/javascript">
    var duoshuoQuery = {short_name:"totoo"};
    (function() {
      var ds = document.createElement('script');
      ds.type = 'text/javascript';ds.async = true;
      ds.id = 'duoshuo-script';
      ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
      ds.charset = 'UTF-8';
      (document.getElementsByTagName('head')[0]
      || document.getElementsByTagName('body')[0]).appendChild(ds);
    })();
  </script>

  
    
    <script src="/vendors/ua-parser-js/dist/ua-parser.min.js?v=0.7.9"></script>
    <script src="/js/src/hook-duoshuo.js"></script>
  






  
  

  
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
  </script>

  <script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
      for (i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
      }
    });
  </script>
  <script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>


  

  

  


</body>
</html>
